---
sidebar: sidebar 
permalink: upgrade-arl-auto-in-chassis/verify-node2-installation.html 
keywords: verifying, verify, node, install, installation, NVRAM, controller, module, modules 
summary: 'Verificare l"installazione del nodo 2 con i moduli sostitutivi quando si utilizza ARL per aggiornare i modelli di controller nello stesso chassis.' 
---
= Verificare l'installazione di node2
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Verificare l'installazione del nodo 2 con i moduli di sistema sostitutivi. Poiché non sono state apportate modifiche alle porte fisiche, non è necessario mappare le porte fisiche dal vecchio nodo 2 al nodo sostituz.2.

.A proposito di questa attività
Una volta avviato il nodo 1 con il modulo di sistema sostitutivo, verificare che sia installato correttamente. È necessario attendere che node2 si unisca al quorum e quindi riprendere l'operazione di sostituzione del controller.

A questo punto della procedura, l'operazione viene messa in pausa mentre il nodo 2 si unisce al quorum.

.Fasi
. Verificare che node2 si sia Unito al quorum:
+
`cluster show -node node2 -fields health`

+
L'output di `health` il campo deve essere `true`.

. Questo passaggio si applica alle seguenti configurazioni di aggiornamento. Per tutti gli altri aggiornamenti di sistema, saltare questo passaggio e andare a <<verify-node2-step3,Fase 3>> :
+
** Cluster switchless a due nodi
** Passare dai sistemi AFF A250 o AFF C250 collegati a un sistema AFF A50, AFF A30, AFF C30 o AFF C60.


+
--
Se node2 non si unisce automaticamente al quorum:

.. Controllare lo spazio IP delle porte e1a ed e1b:
+
`network port show`

.. Se lo spazio IP non è "Cluster", modifica lo spazio IP in "Cluster" su e1a ed e1b:
+
`network port modify -node <node_name> -port <port> -ipspace Cluster`

.. Verificare che lo spazio IP delle porte e1a ed e1b sia "Cluster":
+
`network port show`

.. Migrare i LIF del cluster node2 a e1a ed e1b:
+
`network interface migrate -vserver Cluster -lif <cluster_lif1> -destination-node <node2_name> -destination-port <port_name`



--
. [[verify-node2-step3]]Verifica che node2 e node1 facciano parte dello stesso cluster e che il cluster sia integro:
+
`cluster show`

. Passare alla modalità avanzata dei privilegi:
+
`set advanced`

. Questo passaggio si applica solo agli aggiornamenti di configurazione switchless a due nodi da un AFF A250 o AFF C250 a un AFF A50, AFF A30, AFF C60 o AFF C30. Per tutti gli altri aggiornamenti di sistema, saltare questo passaggio e andare a <<verify-node2-step6,Fase 6>> :
+
Verificare che le porte e4a, e2a, e1a, e1b oppure le porte e4a, e4b, e1a, e1b siano le porte del cluster nel dominio di broadcast "Cluster".

+
I sistemi AFF A50, AFF A30, AFF C30 e AFF C60 condividono porte cluster e HA. È possibile migrare in sicurezza tutti i LIF del cluster a e4a, e4b o e4a, e2a su node1 e node2:

+
.. Elenca le porte domestiche e le porte correnti per tutti i LIF del cluster:
+
`network interface show -role Cluster -fields home-port,curr-port`

.. [[migrate-cluster-lif-step-4b]]Su node1 e node2, migrare i LIF del cluster che utilizzano e1a come porta home su e4a:
+
`network interface migrate -vserver Cluster -lif <cluster_lif1> -destination-node <node> -destination-port e4a`

.. Su node1 e node2, modificare i cluster LIF migrati in <<migrate-cluster-lif-step-4b,sottofase b>> per utilizzare e4a come porta di casa:
+
`network  interface modify -vserver Cluster -lif <cluster_lif> -home-port e4a`

.. Verificare che il cluster sia in quorum:
+
`cluster show`

.. Ripetere <<migrate-cluster-lif-step-4b,sottofase b e sottofase c>> per migrare e modificare il secondo cluster LIF su ciascun nodo in e2a o e4b:
+
Se e2a è presente ed è una porta di rete 100GbE, questa è la seconda porta predefinita del cluster. Se e2a non è una porta di rete 100GbE, ONTAP utilizza e4b come seconda porta del cluster e HA.

.. Rimuovere e1a ed e1b dal dominio di broadcast "Cluster":
+
`broadcast-domain remove-ports -broadcast-domain Cluster -ipspace Cluster -ports <node_name>:e1a`

.. Verificare che solo le porte del cluster e4a, e2a o e4a, e4b siano nel dominio di broadcast "Cluster"
+
`broadcast domain show`

.. Rimuovere i collegamenti via cavo tra e1a node1 ed e1a node2 e tra e1b node1 ed e1b node2 per garantire che vengano utilizzate solo connessioni cluster-HA valide e che non vi sia alcuna connettività ridondante.


. [[verify-node2-step6]]Controllare lo stato dell'operazione di sostituzione del controller e verificare che sia in pausa e nello stesso stato in cui si trovava prima che node2 venisse arrestato per eseguire le attività fisiche di installazione di nuovi controller e spostamento dei cavi:
+
`system controller replace show`

+
`system controller replace show-details`

. Riprendere l'operazione di sostituzione del controller:
+
`system controller replace resume`

. L'operazione di sostituzione del controller viene interrotta per l'intervento con il seguente messaggio:
+
[listing]
----
Cluster::*> system controller replace show
Node          Status                       Error-Action
------------  ------------------------     ------------------------------------
Node2         Paused-for-intervention      Follow the instructions given in
                                           Step Details
Node1         None

Step Details:
--------------------------------------------
To complete the Network Reachability task, the ONTAP network configuration must be manually adjusted to match the new physical network configuration of the hardware. This includes:


1. Re-create the interface group, if needed, before restoring VLANs. For detailed commands and instructions, refer to the "Re-creating VLANs, ifgrps, and broadcast domains" section of the upgrade controller hardware guide for the ONTAP version running on the new controllers.
2. Run the command "cluster controller-replacement network displaced-vlans show" to check if any VLAN is displaced.
3. If any VLAN is displaced, run the command "cluster controller-replacement network displaced-vlans restore" to restore the VLAN on the desired port.
2 entries were displayed.
----
+

NOTE: In questa procedura, la sezione _creazione di VLAN, ifgrps e domini di trasmissione_ è stata rinominata _Ripristino configurazione di rete su node2_.

. Con la sostituzione del controller in stato di pausa, passare a. <<Ripristinare la configurazione di rete sul nodo 2>>.




== Ripristinare la configurazione di rete sul nodo 2

Dopo aver confermato che node2 è in quorum e può comunicare con node1, verificare che le VLAN, i gruppi di interfacce e i domini di broadcast di node1 siano visibili sul node2. Inoltre, verificare che tutte le porte di rete node2 siano configurate nei domini di trasmissione corretti.

.A proposito di questa attività
Per ulteriori informazioni sulla creazione e la ricreazione di VLAN, gruppi di interfacce e domini di trasmissione, fare riferimento a. link:other_references.html["Riferimenti"] Per collegarsi al contenuto di _Network Management_.

.Fasi
. Elencare tutte le porte fisiche sul nodo aggiorno2:
+
`network port show -node node2`

+
Vengono visualizzate tutte le porte di rete fisiche, le porte VLAN e le porte del gruppo di interfacce sul nodo. Da questo output, è possibile visualizzare le porte fisiche spostate in `Cluster` Dominio di broadcast di ONTAP. È possibile utilizzare questo output per agevolare la scelta delle porte da utilizzare come porte membro del gruppo di interfacce, porte di base VLAN o porte fisiche standalone per l'hosting di LIF.

. Elencare i domini di broadcast sul cluster:
+
`network port broadcast-domain show`

. Elencare la raggiungibilità delle porte di rete di tutte le porte sul nodo 2:
+
`network port reachability show -node node2`

+
L'output dovrebbe essere simile all'esempio seguente. I nomi delle porte e delle trasmissioni variano.

+
[listing]
----
Cluster::> reachability show -node node1
  (network port reachability show)
Node      Port     Expected Reachability                Reachability Status
--------- -------- ------------------------------------ ---------------------
Node1
          a0a      Default:Default                      ok
          a0a-822  Default:822                          ok
          a0a-823  Default:823                          ok
          e0M      Default:Mgmt                         ok
          e1a      Cluster:Cluster                      ok
          e1b      -                                    no-reachability
          e2a      -                                    no-reachability
          e2b      -                                    no-reachability
          e3a      -                                    no-reachability
          e3b      -                                    no-reachability
          e7a      Cluster:Cluster                      ok
          e7b      -                                    no-reachability
          e9a      Default:Default                      ok
          e9a-822  Default:822                          ok
          e9a-823  Default:823                          ok
          e9b      Default:Default                      ok
          e9b-822  Default:822                          ok
          e9b-823  Default:823                          ok
          e9c      Default:Default                      ok
          e9d      Default:Default                      ok
20 entries were displayed.
----
+
Nell'esempio precedente, node2 si è avviato e si è Unito al quorum dopo la sostituzione del controller. Dispone di diverse porte che non sono raggiungibilità e che sono in attesa di una scansione di raggiungibilità.

. [[restore_node2_step4]]riparare la raggiungibilità per ciascuna delle porte su node2 con uno stato di raggiungibilità diverso da `ok` utilizzando il seguente comando, nel seguente ordine:
+
`network port reachability repair -node _node_name_  -port _port_name_`

+
--
.. Porte fisiche
.. Porte VLAN


--
+
L'output dovrebbe essere simile al seguente esempio:

+
[listing]
----
Cluster ::> reachability repair -node node2 -port e9d
----
+
[listing]
----
Warning: Repairing port "node2:e9d" may cause it to move into a different broadcast domain, which can cause LIFs to be re-homed away from the port. Are you sure you want to continue? {y|n}:
----
+
Un messaggio di avviso, come mostrato nell'esempio precedente, è previsto per le porte con uno stato di raggiungibilità che potrebbe essere diverso dallo stato di raggiungibilità del dominio di broadcast in cui si trova attualmente. Esaminare la connettività della porta e rispondere `y` oppure `n` a seconda dei casi.

+
Verificare che tutte le porte fisiche abbiano la raggiungibilità prevista:

+
`network port reachability show`

+
Quando viene eseguita la riparazione della raggiungibilità, ONTAP tenta di posizionare le porte nei domini di trasmissione corretti. Tuttavia, se non è possibile determinare la raggiungibilità di una porta e non appartiene a nessuno dei domini di broadcast esistenti, ONTAP creerà nuovi domini di broadcast per queste porte.

. Verificare la raggiungibilità delle porte:
+
`network port reachability show`

+
Quando tutte le porte sono configurate correttamente e aggiunte ai domini di trasmissione corretti, il `network port reachability show` il comando deve riportare lo stato di raggiungibilità come `ok` per tutte le porte connesse e lo stato come `no-reachability` per porte senza connettività fisica. Se una delle porte riporta uno stato diverso da questi due, eseguire la riparazione della raggiungibilità e aggiungere o rimuovere le porte dai propri domini di trasmissione come indicato nella <<restore_node2_step4,Fase 4>>.

. Verificare che tutte le porte siano state inserite nei domini di broadcast:
+
`network port show`

. Verificare che tutte le porte nei domini di trasmissione abbiano configurato la MTU (Maximum Transmission Unit) corretta:
+
`network port broadcast-domain show`

. Ripristinare le porte LIF home, specificando le porte Vserver e LIF home, se presenti, che devono essere ripristinate seguendo questa procedura:
+
.. Elencare eventuali LIF spostati:
+
`displaced-interface show`

.. Ripristinare i nodi home LIF e le porte home:
+
`displaced-interface restore-home-node -node _node_name_ -vserver _vserver_name_ -lif-name _LIF_name_`



. Verificare che tutte le LIF dispongano di una porta home e siano amministrativamente up:
+
`network interface show -fields home-port,status-admin`


